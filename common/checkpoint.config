"""
==============================================================================
Marine Pollution Monitoring System - Flink Checkpoint Configuration
==============================================================================
Configurazione standard per checkpoint e savepoint nei job Flink
"""

import logging
from typing import Optional

# PyFlink imports
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.checkpointing_mode import CheckpointingMode
from pyflink.datastream.state_backend import RocksDBStateBackend, MemoryStateBackend
from pyflink.datastream.checkpoint_storage import FileSystemCheckpointStorage
from pyflink.common.time import Time

logger = logging.getLogger(__name__)

def configure_checkpointing(
    env: StreamExecutionEnvironment,
    checkpoint_interval_ms: int = 300000,  # 5 minuti
    checkpoint_timeout_ms: int = 600000,   # 10 minuti
    min_pause_between_ms: int = 60000,     # 1 minuto
    max_concurrent_checkpoints: int = 1,
    checkpoint_mode: CheckpointingMode = CheckpointingMode.EXACTLY_ONCE,
    externalized_checkpoint_cleanup: Optional[str] = "RETAIN_ON_CANCELLATION",
    state_backend_type: str = "rocksdb",
    checkpoint_dir: str = "hdfs://checkpoint-dir",
    failure_rate_threshold: int = 3,
    failure_rate_interval_ms: int = 3600000  # 1 ora
) -> StreamExecutionEnvironment:
    """
    Configura checkpointing per un job Flink
    
    Args:
        env: L'environment Flink
        checkpoint_interval_ms: Intervallo tra checkpoint in millisecondi
        checkpoint_timeout_ms: Timeout per l'operazione di checkpoint
        min_pause_between_ms: Pausa minima tra checkpoint
        max_concurrent_checkpoints: Numero massimo di checkpoint concorrenti
        checkpoint_mode: Modalità di checkpoint (EXACTLY_ONCE o AT_LEAST_ONCE)
        externalized_checkpoint_cleanup: Comportamento per checkpoint esterni
        state_backend_type: Tipo di state backend ('rocksdb' o 'memory')
        checkpoint_dir: Directory per i checkpoint
        failure_rate_threshold: Soglia di fallimenti per restart
        failure_rate_interval_ms: Intervallo per la soglia di fallimenti
        
    Returns:
        L'environment configurato
    """
    logger.info(f"Configuring checkpointing with interval {checkpoint_interval_ms}ms")
    
    # Abilita checkpoint
    env.enable_checkpointing(checkpoint_interval_ms)
    
    # Ottieni la configurazione
    checkpoint_config = env.get_checkpoint_config()
    
    # Configura modalità
    checkpoint_config.set_checkpointing_mode(checkpoint_mode)
    
    # Configura timeout
    checkpoint_config.set_checkpoint_timeout(checkpoint_timeout_ms)
    
    # Configura intervallo minimo
    checkpoint_config.set_min_pause_between_checkpoints(min_pause_between_ms)
    
    # Configura max concorrenti
    checkpoint_config.set_max_concurrent_checkpoints(max_concurrent_checkpoints)
    
    # Configura comportamento in caso di errore
    checkpoint_config.set_fail_on_checkpointing_errors(False)
    
    # Configura checkpoint esterni
    if externalized_checkpoint_cleanup:
        if externalized_checkpoint_cleanup == "RETAIN_ON_CANCELLATION":
            from pyflink.datastream.checkpoint_config import ExternalizedCheckpointCleanup
            checkpoint_config.enable_externalized_checkpoints(
                ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION)
        elif externalized_checkpoint_cleanup == "DELETE_ON_CANCELLATION":
            from pyflink.datastream.checkpoint_config import ExternalizedCheckpointCleanup
            checkpoint_config.enable_externalized_checkpoints(
                ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION)
    
    # Configura state backend
    if state_backend_type.lower() == 'rocksdb':
        # RocksDB è meglio per grandi stati
        backend = RocksDBStateBackend(checkpoint_dir, True)
        env.set_state_backend(backend)
    else:
        # Memory è più veloce ma limitato dalla RAM
        backend = MemoryStateBackend(checkpoint_dir, True)
        env.set_state_backend(backend)
    
    # Configura restart strategy
    env.set_restart_strategy("failure-rate", 
                             restart_attempts_per_interval=failure_rate_threshold,
                             failure_rate_interval=Time.milliseconds(failure_rate_interval_ms),
                             delay_between_attempts=Time.seconds(10))
    
    logger.info("Checkpointing configured successfully")
    return env


def configure_savepoint(
    env: StreamExecutionEnvironment,
    savepoint_dir: str = "hdfs://savepoint-dir"
) -> StreamExecutionEnvironment:
    """
    Configura savepoint per un job Flink
    
    Args:
        env: L'environment Flink
        savepoint_dir: Directory per i savepoint
        
    Returns:
        L'environment configurato
    """
    # Configura directory per savepoint
    env.set_default_savepoint_directory(savepoint_dir)
    
    logger.info(f"Savepoint directory configured: {savepoint_dir}")
    return env