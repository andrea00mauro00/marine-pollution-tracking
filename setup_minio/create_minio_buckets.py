import boto3
from botocore.exceptions import ClientError
import time
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(levelname)s] %(asctime)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# MinIO endpoint and credentials
MINIO_ENDPOINT = "minio:9000"
ACCESS_KEY = "minioadmin"
SECRET_KEY = "minioadmin"

# Buckets aligned with our Marine Pollution Monitoring System architecture
BUCKETS = [
    # Medallion architecture main buckets
    "bronze",       # Raw standardized data (buoy readings, satellite metadata)
    "silver",       # Processed and analyzed data
    "gold",         # Business insights (hotspots, predictions, alerts)
]

# Structured folder hierarchy based on the medallion architecture
# Using year=YYYY/month=MM/day=DD partitioning for consistency and optimization
FOLDER_STRUCTURE = {
    "bronze": [
        # Buoy data with partitioning
        "buoy_data/year=2025/month=07/day=07/",
        
        # Satellite imagery with partitioning
        "satellite_imagery/sentinel2/year=2025/month=07/day=07/"
    ],
    "silver": [
        # Analyzed data from buoy sensors
        "analyzed_data/buoy/year=2025/month=07/day=07/",
        
        # Analyzed data from satellite imagery
        "analyzed_data/satellite/year=2025/month=07/day=07/"
    ],
    "gold": [
        # Pollution hotspots identified by analysis
        "hotspots/year=2025/month=07/day=07/",
        
        # Predictions of pollution spread
        "predictions/year=2025/month=07/day=07/",
        
        # Alert events generated by the system
        "alerts/year=2025/month=07/day=07/"
    ]
}

def create_buckets():
    """Create all required buckets in MinIO for the pollution monitoring system"""
    # Wait for MinIO to be ready
    logger.info("Waiting for MinIO to be ready...")
    time.sleep(10)
    
    # Create S3 client
    s3 = boto3.client(
        's3',
        endpoint_url=f'http://{MINIO_ENDPOINT}',
        aws_access_key_id=ACCESS_KEY,
        aws_secret_access_key=SECRET_KEY
    )
    
    # Create buckets
    for bucket in BUCKETS:
        try:
            s3.head_bucket(Bucket=bucket)
            logger.info(f"Bucket '{bucket}' already exists")
        except ClientError:
            try:
                s3.create_bucket(Bucket=bucket)
                logger.info(f"Created bucket '{bucket}'")
                
                # Create folder structure (by adding empty objects with folder prefixes)
                if bucket in FOLDER_STRUCTURE:
                    for folder in FOLDER_STRUCTURE[bucket]:
                        s3.put_object(Bucket=bucket, Key=folder, Body='')
                        logger.info(f"Created folder structure '{folder}' in bucket '{bucket}'")
                
            except Exception as e:
                logger.error(f"Failed to create bucket '{bucket}': {e}")

def check_buckets_health(s3_client):
    """Verify all buckets are accessible and report their status"""
    logger.info("Checking buckets health...")
    
    for bucket in BUCKETS:
        try:
            response = s3_client.list_objects_v2(Bucket=bucket, MaxKeys=1)
            logger.info(f"Bucket '{bucket}' is healthy. Contains {response.get('KeyCount', 0)} objects")
        except Exception as e:
            logger.warning(f"Bucket '{bucket}' health check failed: {e}")

if __name__ == "__main__":
    # Try multiple times in case MinIO is not yet ready
    max_attempts = 5
    s3_client = None
    
    for attempt in range(max_attempts):
        try:
            # Create S3 client
            s3_client = boto3.client(
                's3',
                endpoint_url=f'http://{MINIO_ENDPOINT}',
                aws_access_key_id=ACCESS_KEY,
                aws_secret_access_key=SECRET_KEY
            )
            
            # Create buckets
            create_buckets()
            logger.info("Bucket creation completed successfully")
            
            # Verify buckets are accessible
            check_buckets_health(s3_client)
            
            break
        except Exception as e:
            logger.error(f"Attempt {attempt+1}/{max_attempts} failed: {e}")
            if attempt < max_attempts - 1:
                logger.info("Retrying in 10 seconds...")
                time.sleep(10)
            else:
                logger.critical("Maximum attempts reached. Please check MinIO availability.")